{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyopenssl in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (23.0.0)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1 in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (0.4.8)\n",
      "Requirement already satisfied: urllib3 in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (1.26.16)\n",
      "Requirement already satisfied: cryptography<40,>=38.0.0 in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (from pyopenssl) (39.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (from cryptography<40,>=38.0.0->pyopenssl) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages (from cffi>=1.12->cryptography<40,>=38.0.0->pyopenssl) (2.21)\n",
      "Installing collected packages: ndg-httpsclient\n",
      "Successfully installed ndg-httpsclient-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyopenssl ndg-httpsclient pyasn1 urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4uLrcJ7hmt-2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import random\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import MaxPooling2D,Conv2D\n",
    "#from keras.layers.advanced_activations import L.LeakyReLU\n",
    "from keras import layers as L\n",
    "\n",
    "df = pd.read_csv('./braille_dataNew.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lgOJJAwkmuB3"
   },
   "outputs": [],
   "source": [
    "#  It's reading in the data from the csv file\n",
    "#  It's creating a dictionary of the target values\n",
    "#  It's reading in the images from the urls\n",
    "#  It's resizing the images to 28x28\n",
    "#  It's normalizing the images between values 0 to 1 \n",
    "alphabet = list(string.ascii_lowercase)\n",
    "cur_pos = 0\n",
    "target = {}\n",
    "for letter in alphabet:\n",
    "    target[letter] = [0] * 27\n",
    "    target[letter][cur_pos] = 1\n",
    "    cur_pos += 1\n",
    "target[' '] = [0] * 27\n",
    "target[' '][26] = 1\n",
    "    \n",
    "data = []\n",
    "for i, row in df.iterrows():\n",
    "    picture = []\n",
    "    url = row['Labeled Data']\n",
    "    label = row['Label']\n",
    "    cur_target = target[label[11]]\n",
    "    x = urllib.request.urlopen(url)\n",
    "    resp = x.read()\n",
    "    image = np.array(bytearray(resp), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (28,28))\n",
    "    image = image.astype(np.float32)/255.0\n",
    "    picture.append(image)\n",
    "    picture.append(cur_target)\n",
    "    data.append(picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_550UUgvmuGk"
   },
   "outputs": [],
   "source": [
    "length = len(data)\n",
    "for i in range(length):\n",
    "    label = data[i][1]   \n",
    "    index = label.index(1)  # Find the index of the element equal to 1\n",
    "    data[i][1] = [0] * 27       \n",
    "    data[i][1][index] = 1    # Set the identified index to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rVO2IehDmuJs",
    "outputId": "36697fe6-23c6-4551-c708-378d12c81218"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nitesh/anaconda3/envs/dl/lib/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#creates array to test, train and validate the model \n",
    "\n",
    "random.shuffle(data)\n",
    "\n",
    "data = np.asarray(data)\n",
    "train_dataset = data[:1124]\n",
    "test_dataset = data[1124:1264]\n",
    "valid_dataset = data[1264:1404]\n",
    "\n",
    "train_dataset_img = np.array(train_dataset[:,0])\n",
    "train_dataset_label = np.array(train_dataset[:,1])\n",
    "test_dataset_img = np.array(test_dataset[:,0])\n",
    "test_dataset_label = np.array(test_dataset[:,1])\n",
    "valid_dataset_img = np.array(valid_dataset[:,0])\n",
    "valid_dataset_label = np.array(valid_dataset[:,1])\n",
    "\n",
    "#to expand dimension for further processing \n",
    "\n",
    "a=np.expand_dims(train_dataset_img[0],axis=0)\n",
    "b=np.expand_dims(train_dataset_img[1],axis=0)\n",
    "tr_ds_img=np.append(a,b,axis=0)\n",
    "for i in range(2,1124):\n",
    "    x=np.expand_dims(train_dataset_img[i],axis=0)\n",
    "    tr_ds_img=np.append(tr_ds_img,x,axis=0)\n",
    "    \n",
    "a1=np.expand_dims(test_dataset_img[0],axis=0)\n",
    "b1=np.expand_dims(test_dataset_img[1],axis=0)\n",
    "ts_ds_img=np.append(a1,b1,axis=0)\n",
    "for i in range(2,140):\n",
    "    x1=np.expand_dims(test_dataset_img[i],axis=0)\n",
    "    ts_ds_img=np.append(ts_ds_img,x1,axis=0)\n",
    "\n",
    "a2=np.expand_dims(valid_dataset_img[0],axis=0)\n",
    "b2=np.expand_dims(valid_dataset_img[1],axis=0)\n",
    "va_ds_img=np.append(a2,b2,axis=0)\n",
    "for i in range(2,140):\n",
    "    x=np.expand_dims(valid_dataset_img[i],axis=0)\n",
    "    va_ds_img=np.append(va_ds_img,x,axis=0)\n",
    "\n",
    "tr_ds_lb = np.expand_dims(train_dataset_label[0],axis=0)\n",
    "for i in range(1,1124):\n",
    "    x3 = np.expand_dims(train_dataset_label[i],axis=0)\n",
    "    tr_ds_lb = np.append(tr_ds_lb,x3,axis=0)\n",
    "\n",
    "ts_ds_lb = np.expand_dims(test_dataset_label[0],axis=0)\n",
    "for i in range(1,140):\n",
    "    x4 = np.expand_dims(test_dataset_label[i],axis=0)\n",
    "    ts_ds_lb = np.append(ts_ds_lb,x4,axis=0)\n",
    "    \n",
    "va_ds_lb = np.expand_dims(valid_dataset_label[0],axis=0)\n",
    "for i in range(1,140):\n",
    "    x5 = np.expand_dims(valid_dataset_label[i],axis=0)\n",
    "    va_ds_lb = np.append(va_ds_lb,x5,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "456s6rfSmuNX",
    "outputId": "b79071c2-9ea5-4bd5-f098-7cf841b42234"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-29 23:53:53.678655: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-05-29 23:53:53.680085: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-29 23:53:53.683204: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-05-29 23:53:53.929274: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-05-29 23:53:53.929928: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 5s 110ms/step - loss: 3.2997 - accuracy: 0.0544 - val_loss: 3.2998 - val_accuracy: 0.0071\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 3.2962 - accuracy: 0.0398 - val_loss: 3.3039 - val_accuracy: 0.0071\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 3.2943 - accuracy: 0.0351 - val_loss: 3.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 3.2938 - accuracy: 0.0392 - val_loss: 3.3085 - val_accuracy: 0.0286\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 3.2892 - accuracy: 0.0466 - val_loss: 3.3011 - val_accuracy: 0.0357\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 3.1043 - accuracy: 0.1284 - val_loss: 2.1779 - val_accuracy: 0.2857\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 70ms/step - loss: 1.3693 - accuracy: 0.6188 - val_loss: 0.7347 - val_accuracy: 0.8214\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.5308 - accuracy: 0.8763 - val_loss: 0.5916 - val_accuracy: 0.8643\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.5343 - accuracy: 0.8646 - val_loss: 0.3487 - val_accuracy: 0.9071\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.3013 - accuracy: 0.9211 - val_loss: 0.5579 - val_accuracy: 0.8786\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.2262 - accuracy: 0.9452 - val_loss: 0.3342 - val_accuracy: 0.8857\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2110 - accuracy: 0.9505 - val_loss: 0.2362 - val_accuracy: 0.9214\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.1509 - accuracy: 0.9617 - val_loss: 0.3849 - val_accuracy: 0.8786\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.1976 - accuracy: 0.9408 - val_loss: 0.4737 - val_accuracy: 0.8857\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.1853 - accuracy: 0.9491 - val_loss: 0.2349 - val_accuracy: 0.9286\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.2177 - accuracy: 0.9403 - val_loss: 0.2204 - val_accuracy: 0.9500\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 68ms/step - loss: 0.1005 - accuracy: 0.9769 - val_loss: 0.2018 - val_accuracy: 0.9429\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 67ms/step - loss: 0.1243 - accuracy: 0.9674 - val_loss: 0.2671 - val_accuracy: 0.9286\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.1125 - accuracy: 0.9741 - val_loss: 0.2468 - val_accuracy: 0.9286\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.0918 - accuracy: 0.9816 - val_loss: 0.2641 - val_accuracy: 0.9500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2917 - accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "epochs= 20 #no of iteration over data set \n",
    "batch_size = 32 #number of training examples that are processed at a time by the model after these examples are evaluated the parameters are updated\n",
    "num_classes = 27 #output shape of the model, ie the o/p layer will have 27 neurons  \n",
    "\n",
    "braille_model = Sequential()\n",
    "braille_model.add(Conv2D(16, kernel_size=(5,5), activation='linear', input_shape=(28,28,3), padding='same', strides=1))\n",
    "braille_model.add(L.LeakyReLU(alpha = 0.1))\n",
    "braille_model.add(MaxPooling2D((2,2)))\n",
    "braille_model.add(Conv2D(32, kernel_size=(5,5), activation ='linear', padding='same', strides=1))\n",
    "braille_model.add(L.LeakyReLU(alpha = 0.1))\n",
    "braille_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "braille_model.add(Dropout(0.25)) #dropout accuracy reduced to 93\n",
    "braille_model.add(Conv2D(64, kernel_size=(5,5), activation='linear', padding='same',strides=1))\n",
    "braille_model.add(L.LeakyReLU(alpha=0.1))\n",
    "braille_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "braille_model.add(Conv2D(128, kernel_size=(5,5), activation='linear', padding='same',strides=1))\n",
    "braille_model.add(L.LeakyReLU(alpha=0.1))\n",
    "braille_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "braille_model.add(Flatten())\n",
    "braille_model.add(Dense(256,activation='linear'))\n",
    "braille_model.add(L.LeakyReLU(alpha=0.1))\n",
    "braille_model.add(Dense(num_classes,activation='softmax')) #softmax fo multiclass classification\n",
    "\n",
    "braille_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "#fit the model\n",
    "braille_train = braille_model.fit(tr_ds_img ,tr_ds_lb , batch_size=batch_size , epochs=epochs, verbose=1, validation_data=(va_ds_img, va_ds_lb))\n",
    "\n",
    "test_eval = braille_model.evaluate(ts_ds_img,ts_ds_lb,verbose=1)\n",
    "\n",
    "braille_model.save('braille_train.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1gS534RmuoQ",
    "outputId": "36b120fc-3ce0-46a1-d36c-1ca9ee8d96cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        1216      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 28, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 27)                6939      \n",
      "=================================================================\n",
      "Total params: 310,203\n",
      "Trainable params: 310,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#FOR MODEL SUMMARY\n",
    "braille_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbraille_train.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"braille_train.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
